{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "optimal_proba_cutoff = sorted(list(zip(np.abs(tpr - fpr), preds_probas)), key=lambda i: i[0], reverse=True)[0][1]\n",
    "roc_predictions = np.array([1 if i >= optimal_proba_cutoff else 0 for i in preds_probas])\n",
    "\n",
    "optimal_proba_cutoff\n",
    "\n",
    "print(\"Accuracy Score After Thresholding: {}\".format(accuracy_score(y_true, roc_predictions)))\n",
    "print(\"Precision Score After Thresholding: {}\".format(precision_score(y_true, roc_predictions)))\n",
    "print(\"Recall Score After Thresholding: {}\".format(recall_score(y_true, roc_predictions)))\n",
    "print(\"F1 Score After Thresholding: {}\".format(f1_score(y_true, roc_predictions)))\n",
    "\n",
    "print(classification_report(y_true, roc_predictions, target_names=[\"CG\",\"OR\"]))checkpoint = \"../../data/classification/models/detector-base.pt\"\n",
    "data = torch.load(checkpoint, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"roberta-base\"\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(data['model_state_dict'],strict=False)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Probability: 0.0002431118191452697\n",
      "Fake Probability: 0.9997568726539612\n",
      "All Tokens: 351\n",
      "Used Tokens: 351\n"
     ]
    }
   ],
   "source": [
    "device=\"cuda\"\n",
    "query = \"\"\"I liked nothing about this dress. The only reason I gave it 4 stars is because I ordered the size 6.5 and it fit perfectly. The fabric is a nice thin material and the color is vibrant. It's a little thin on me but it's worth it. The material is soft and comfortable. I love the color and the fit. I'm 5'4\" and it fits just right. I'm a size 6 and it's a bit long on me so I ordered a 6 in order to fit the smaller size. I'm 5'3\" and it fits perfect and I got it in a medium. It's a nice dress and I'm very pleased with it. I like that it's a bit small for me and I can wear it with a top or skirt. I also like that the fabric is made of a good material. I wear a size 5 and it fits well. I'm 5'3\" and it fits just right. I'm 5'6\" and it fits just right. I'm 5'4\" and it fits just right. I wear a size 10.5 and it's a little tight on me. I have a small waist and it's not too tight on me. It's a nice little dress. I will buy more colors.Very nice dress.  It is well made and it is very comfortable.  I received a free sample and will see if I can wear it again.  I would definitely buy another one.  I am very happy with this dress.I love these boots!  I have been wearing them for almost 8 months now and I love them so much that I purchased a second pair.  They are very comfortable and look great. \"\"\"\n",
    "tokens = tokenizer.encode(query)\n",
    "all_tokens = len(tokens)\n",
    "tokens = tokens[:tokenizer.model_max_length - 2]\n",
    "used_tokens = len(tokens)\n",
    "tokens = torch.tensor([tokenizer.bos_token_id] + tokens + [tokenizer.eos_token_id]).unsqueeze(0)\n",
    "mask = torch.ones_like(tokens)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n",
    "    probs = logits.softmax(dim=-1)\n",
    "\n",
    "fake, real = probs.detach().cpu().flatten().numpy().tolist()\n",
    "\n",
    "print(f\"Real Probability: {real}\\nFake Probability: {fake}\\nAll Tokens: {all_tokens}\\nUsed Tokens: {used_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Probability: 0.9997749924659729\n",
      "Fake Probability: 0.00022505233937408775\n",
      "All Tokens: 408\n",
      "Used Tokens: 408\n"
     ]
    }
   ],
   "source": [
    "device=\"cuda\"\n",
    "query = \"\"\"I work in the wedding industry and have to work long days, on my feet, outside in the heat, and have to look professional. I've spent a ridiculous amount of money on high end dress shoes like Merrels and just have not been able to find a pair that are comfortable to wear all day. Both for my feet and my back. Enter the Sanuk yoga sling!!! These shoes are amazingly comfortable. Though, I will admit it took a few wears to get used to the feel of the yoga matte bottom. At first, it felt a little \"sticky\" to me, and the fabric part that goes through the toe area was a little thick and took some getting used to. I wore them for a few days before taking them out on a job and I can't get over how comfortable they are. Ii have been wearing these shoes now for 3 months, every work day and I am THRILLED. No more back pain, no more sore feet. I also wear these sometimes during my off time,mans every time I wear them, I get compliments on how cute and comfortable they look. The great thing about these shoes is the yoga matte bottom. It helps your feet grip to the shoe a bit, so your foot can just walk normally, without having to grip the shoe. You may not realize it, but with a lot of Sandals, your foot is having to work to keep the shoe on, changing the way you walk and stand and ultimately causing foot and back pain. Not with these! Also, the soft linen sits comfortably on your skin and breathes nicely in the heat. The only downside is the funky tan lines, which is why I am sure to alternate shoes on my days off, especially if I plan to be outside for most of the day. If it were not for that, I think these might be the only shoes I'd wear all summer. If you are looking for a reasonable priced, comfortable shoe that you can wear and walk in all day.\"\"\"\n",
    "tokens = tokenizer.encode(query)\n",
    "all_tokens = len(tokens)\n",
    "tokens = tokens[:tokenizer.model_max_length - 2]\n",
    "used_tokens = len(tokens)\n",
    "tokens = torch.tensor([tokenizer.bos_token_id] + tokens + [tokenizer.eos_token_id]).unsqueeze(0)\n",
    "mask = torch.ones_like(tokens)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n",
    "    probs = logits.softmax(dim=-1)\n",
    "\n",
    "fake, real = probs.detach().cpu().flatten().numpy().tolist()\n",
    "\n",
    "print(f\"Real Probability: {real}\\nFake Probability: {fake}\\nAll Tokens: {all_tokens}\\nUsed Tokens: {used_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_label_dict = {\"CG\" : 0, \"OR\" : 1}\n",
    "def encode_label(x):\n",
    "    return encoded_label_dict.get(x,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/classification/data/deception_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target\"] = df[\"label\"].apply(lambda x: encode_label(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CG    800\n",
       "OR    800\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(query, model, tokenizer, device=\"cuda\"):\n",
    "    tokens = tokenizer.encode(query)\n",
    "    all_tokens = len(tokens)\n",
    "    tokens = tokens[:tokenizer.model_max_length - 2]\n",
    "    used_tokens = len(tokens)\n",
    "    tokens = torch.tensor([tokenizer.bos_token_id] + tokens + [tokenizer.eos_token_id]).unsqueeze(0)\n",
    "    mask = torch.ones_like(tokens)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n",
    "        probs = logits.softmax(dim=-1)\n",
    "\n",
    "    fake, real = probs.detach().cpu().flatten().numpy().tolist()\n",
    "    return real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997749924659729"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"I work in the wedding industry and have to work long days, on my feet, outside in the heat, and have to look professional. I've spent a ridiculous amount of money on high end dress shoes like Merrels and just have not been able to find a pair that are comfortable to wear all day. Both for my feet and my back. Enter the Sanuk yoga sling!!! These shoes are amazingly comfortable. Though, I will admit it took a few wears to get used to the feel of the yoga matte bottom. At first, it felt a little \"sticky\" to me, and the fabric part that goes through the toe area was a little thick and took some getting used to. I wore them for a few days before taking them out on a job and I can't get over how comfortable they are. Ii have been wearing these shoes now for 3 months, every work day and I am THRILLED. No more back pain, no more sore feet. I also wear these sometimes during my off time,mans every time I wear them, I get compliments on how cute and comfortable they look. The great thing about these shoes is the yoga matte bottom. It helps your feet grip to the shoe a bit, so your foot can just walk normally, without having to grip the shoe. You may not realize it, but with a lot of Sandals, your foot is having to work to keep the shoe on, changing the way you walk and stand and ultimately causing foot and back pain. Not with these! Also, the soft linen sits comfortably on your skin and breathes nicely in the heat. The only downside is the funky tan lines, which is why I am sure to alternate shoes on my days off, especially if I plan to be outside for most of the day. If it were not for that, I think these might be the only shoes I'd wear all summer. If you are looking for a reasonable priced, comfortable shoe that you can wear and walk in all day.\"\"\"\n",
    "predict(query,model,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "preds, preds_probas = [],[]\n",
    "for i, row in test_df.iterrows():\n",
    "    query = row[\"text_\"]\n",
    "    pred = predict(query,model,tokenizer)\n",
    "    preds_probas.append(pred)\n",
    "    if pred >= 0.5:\n",
    "        preds.append(1)\n",
    "    else:\n",
    "        preds.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[115, 685],\n",
       "       [ 47, 753]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = test_df.target.values\n",
    "y_pred = preds\n",
    "confusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "acc = accuracy_score(y_true,y_pred)\n",
    "precision = precision_score(y_true,y_pred)\n",
    "recall = recall_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.25; Precision:52.36439499304589; Recall:94.125\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {acc*100}; Precision:{precision*100}; Recall:{recall*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CG       0.71      0.14      0.24       800\n",
      "          OR       0.52      0.94      0.67       800\n",
      "\n",
      "    accuracy                           0.54      1600\n",
      "   macro avg       0.62      0.54      0.46      1600\n",
      "weighted avg       0.62      0.54      0.46      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=[\"CG\",\"OR\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# roc curve for models\n",
    "fpr, tpr, thresh = roc_curve(y_true, preds_probas, pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_true))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_true, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5951039062500001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# auc scores\n",
    "auc_score = roc_auc_score(y_true, preds_probas)\n",
    "\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# plot roc curves\n",
    "plt.plot(fpr, tpr, linestyle='--',color='orange', label='finetuned-roberta')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "optimal_proba_cutoff = sorted(list(zip(np.abs(tpr - fpr), preds_probas)), key=lambda i: i[0], reverse=True)[0][1]\n",
    "roc_predictions = np.array([1 if i >= optimal_proba_cutoff else 0 for i in preds_probas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998264908790588"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_proba_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score Before and After Thresholding: 0.5425, 0.51625\n",
      "Precision Score Before and After Thresholding: 0.5236439499304589, 0.5844155844155844\n",
      "Recall Score Before and After Thresholding: 0.94125, 0.1125\n",
      "F1 Score Before and After Thresholding: 0.6729222520107238, 0.18867924528301885\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score Before and After Thresholding: {}, {}\".format(accuracy_score(y_true, y_pred), accuracy_score(y_true, roc_predictions)))\n",
    "print(\"Precision Score Before and After Thresholding: {}, {}\".format(precision_score(y_true, y_pred), precision_score(y_true, roc_predictions)))\n",
    "print(\"Recall Score Before and After Thresholding: {}, {}\".format(recall_score(y_true, y_pred), recall_score(y_true, roc_predictions)))\n",
    "print(\"F1 Score Before and After Thresholding: {}, {}\".format(f1_score(y_true, y_pred), f1_score(y_true, roc_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report After Thresholding\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CG       0.51      0.92      0.66       800\n",
      "          OR       0.58      0.11      0.19       800\n",
      "\n",
      "    accuracy                           0.52      1600\n",
      "   macro avg       0.55      0.52      0.42      1600\n",
      "weighted avg       0.55      0.52      0.42      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report After Thresholding\\n\")\n",
    "print(classification_report(y_true, roc_predictions, target_names=[\"CG\",\"OR\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing predictions to disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df_rows = []\n",
    "for i, row in valid_df.reset_index().iterrows():\n",
    "    query = row[\"text_\"]\n",
    "    pred_prob = preds_probas[i]\n",
    "    pred_label = preds[i]\n",
    "    preds_df_rows.append([pred_prob,pred_label])\n",
    "preds_df = pd.DataFrame(preds_df_rows, columns=[\"GPT2_Detector_Model_Probability\",\"GPT2_Detector_Model_Prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.to_csv(\"../../data/classification/data/gpt2_detector_predictions.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
